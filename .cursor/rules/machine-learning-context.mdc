---
description: 
globs: 
alwaysApply: false
---
Please navigate first through the directory to understand the project.

It is important for you to see the libraries that we are using, and our main two .py files:

1.[data_scrape.py](mdc:data_scrape.py): 
   - Scrapes the main property listings.
   - Collects basic property information and sales history.
   - Outputs two files:
        -[scraped_properties.csv](mdc:data/scraped_properties.csv):  Consolidated data with one row per property.
        -[scraped_properties_expanded.csv](mdc:data/scraped_properties_expanded.csv): Detailed data with one row per sale.

2.[site_processer.py](mdc:site_processer.py):
    - Takes the links from [scraped_properties.csv](mdc:data/scraped_properties.csv).
    - Visits each property's detailed page
    - Collects additional property details like:
       - Living area
       - Number of rooms
       - Construction year
       - Floor information
       - Heating type
       - Wall material
       - Weighted area
       - Roof type

The information is taken from the real state danish website called "Boligsiden". We are planning to use the data with the following purposes:

We would like to conduct a paper on foreclosure sales annually in the  Region Hovedstaden. We find this particularly interesting because of Copenhagen's expensive housing market. By analyzing the types of properties being sold for foreclosure we would aim to identify potential patterns to what type of houses are being sold on foreclosure and see if we can gain any insights into the dynamics of these property sales in the region.

We aim to combine the two data sets to get a more precise insight into what types of houses are being foreclosed and in which cities. Furthermore we would like to look at whether the sales price has any impact on the foreclosure rates and whether location impacts both price and volume of foreclosures.
By analyzing sales over time we also hope to get a clearer view of how the number of foreclosed properties change annually across different cities. We also want to see whether property details like:
       - Living area
       - Number of rooms
       - Construction year
       - Floor information
       - Heating type
       - Wall material
       - Weighted area
       - Roof type
Affect the possibility for a property to be forclosed by analyzing the data using ML algorithms. Because of this, the data needs to be as clean, and as populated as possible, in order for the ML algorithms to detect any effect that the features might have. Your task is to help me:

1. Troubleshooting the code and optimising the data scraping tasks, so that we do as little work as possible locally, trying to get as much data as we can from every single run, we do not want to disturb the hosts of the website.
2. Making sure it is working, by taking close looks at the logs, and by mantaining good coding practices.
3. Tackling any innefficiencies that you detect in the code.
4. Keeping the code clean.
5. Making sure the data is consistent, and the results are correct.

6. Making sure it is optimised for ML purposes, and suggesting any feature engineering that can be done to the exising data in order to improve the accuracy of our future ML algorithms.